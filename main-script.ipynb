{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "from zipfile import BadZipFile\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import csv\n",
    "from selenium.common.exceptions import NoSuchElementException   \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texturehaven(directory_output, csv_directory):\n",
    "    \n",
    "    if not os.path.exists(directory_output):\n",
    "            os.mkdir(directory_output)\n",
    "        \n",
    "    if not os.path.exists(csv_directory):\n",
    "            os.mkdir(csv_directory)\n",
    "    \n",
    "    def download_files(url, save_path, chunk_size=1024):\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(save_path, 'wb') as fd:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                fd.write(chunk)\n",
    "            \n",
    "\n",
    "    def get_links_to_csv(base_url, file_name_to_store, anchor_grid_id, anchor_css_selector=None):\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(base_url)\n",
    "\n",
    "        anchor_grid = driver.find_element_by_id(anchor_grid_id)\n",
    "\n",
    "        if anchor_css_selector == None:\n",
    "            anchor_tags = anchor_grid.find_elements_by_css_selector(\"a\")\n",
    "        else:\n",
    "            anchor_tags = anchor_grid.find_elements_by_css_selector(anchor_css_selector)\n",
    "\n",
    "        texture_csv_rows = []\n",
    "\n",
    "        for anchor in anchor_tags:\n",
    "            parsed_url = anchor.get_attribute(\"href\")\n",
    "            title = parsed_url.split('=')[1]\n",
    "            csv_row = {\n",
    "                'title': title.lower(),\n",
    "                'url': parsed_url,\n",
    "                'resolution': '2k'\n",
    "            }\n",
    "            texture_csv_rows.append(csv_row )\n",
    "\n",
    "        driver.close()\n",
    "        # print(texture_csv_rows)\n",
    "\n",
    "        texture_csv = pd.DataFrame(texture_csv_rows)\n",
    "        texture_csv.to_csv(file_name_to_store)\n",
    "\n",
    "\n",
    "    #'//*[@id=\"preview-download\"]/div[2]/div[1]/div[3]/div[2]/a[1]'\n",
    "    def get_download_links_to_csv(csv_name_with_links, resolution, xPath):\n",
    "        texture_csv_rows = []\n",
    "\n",
    "        driver = webdriver.Chrome()\n",
    "\n",
    "        with open(csv_name_with_links, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                driver.get(row['url'])\n",
    "                download_anchor = driver.find_element_by_xpath(xPath)\n",
    "                download_url = download_anchor.get_attribute(\"href\")\n",
    "                csv_row = {\n",
    "                    'title': row['title'],\n",
    "                    'url': row['url'],\n",
    "                    'resolution': resolution,\n",
    "                    'download_url': download_url\n",
    "                }\n",
    "                texture_csv_rows.append(csv_row )\n",
    "\n",
    "        driver.close()\n",
    "\n",
    "        texture_csv = pd.DataFrame(texture_csv_rows)\n",
    "        texture_csv.to_csv(csv_name_with_links)\n",
    "\n",
    "\n",
    "    def download_zip_files(csv_with_download_links, dir_output):\n",
    "        \n",
    "        if not os.path.exists(dir_output):\n",
    "            os.mkdir(dir_output)\n",
    "            \n",
    "        file_path_template = re.compile(r'\\/([^/]+$)')\n",
    "\n",
    "        with open(csv_with_download_links, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                file_path = file_path_template.search(row['download_url']).group(1)\n",
    "                download_files(row['download_url'], f'{dir_output}{file_path.lower()}')\n",
    "                \n",
    "\n",
    "    def color_map_count(map_dir):\n",
    "        list_of_maps = os.listdir(map_dir)\n",
    "        color_map_count = 0\n",
    "        \n",
    "        for map_type in list_of_maps:\n",
    "            if 'color' in os.path.basename(map_type):\n",
    "                color_map_count += 1\n",
    "        \n",
    "        return color_map_count \n",
    "            \n",
    "            \n",
    "    def remove_other_color_maps(map_dir, main_color_name):\n",
    "        list_of_maps = os.listdir(map_dir)\n",
    "        \n",
    "        for map_type in list_of_maps:\n",
    "            map_name = os.path.basename(map_type)\n",
    "            if 'color' in map_name and not main_color_name in map_name:\n",
    "                os.remove(f'{map_dir}/{map_name}')\n",
    "\n",
    "                \n",
    "    def fix_map_naming(map_dir, old_folder_name, new_folder_name):\n",
    "        list_of_maps = os.listdir(map_dir)\n",
    "        \n",
    "        for map_type in list_of_maps:\n",
    "            map_name = os.path.basename(map_type)\n",
    "            new_name = map_name.replace(old_folder_name, new_folder_name)\n",
    "            os.rename(f'{map_dir}/{map_name}', f'{map_dir}/{new_name}')\n",
    "            \n",
    "    def fix_color_maps(map_dir):\n",
    "        color_maps_count = color_map_count(map_dir)\n",
    "        old_name = os.path.basename(map_dir)\n",
    "        \n",
    "        if color_maps_count > 1:       \n",
    "            print(map_dir)\n",
    "            for color_map_number in range(1, color_maps_count):\n",
    "                new_copy_path =  f'{map_dir}_{color_map_number + 1}'\n",
    "                shutil.copytree(map_dir, new_copy_path)\n",
    "                remove_other_color_maps(new_copy_path, f'color_0{color_map_number + 1}')\n",
    "                new_name = os.path.basename(new_copy_path)\n",
    "                \n",
    "            os.rename(map_dir, f'{map_dir}_1')\n",
    "            remove_other_color_maps(f'{map_dir}_1', 'color_01')\n",
    "    \n",
    "            \n",
    "    def fix_maptypes(map_dir, source_name):\n",
    "        list_of_maps = os.listdir(map_dir)\n",
    "        \n",
    "        for map_type in list_of_maps:\n",
    "            map_file_name = os.path.basename(map_type)\n",
    "            name_changed = False\n",
    "            \n",
    "            for map_key, map_label in texture_map_labels[source_name].items():\n",
    "\n",
    "                if map_key in map_file_name:\n",
    "                    old_name = map_file_name\n",
    "                    map_file_name = map_file_name.replace(map_key, map_label)\n",
    "                    os.rename(f'{map_dir}/{old_name}', f'{map_dir}/{source_name}_{map_file_name.lower().replace(\"-\", \"--\")}')\n",
    "                    name_changed = True\n",
    "                    break\n",
    "            if not name_changed:\n",
    "                os.rename(f'{map_dir}/{map_file_name}', f'{map_dir}/{source_name}_{map_file_name.lower().replace(\"-\", \"--\")}')\n",
    "\n",
    "    \n",
    "    def extract_files(zip_dir, extracting_dir):\n",
    "        zip_list = os.listdir(zip_dir)\n",
    "\n",
    "        for zip_file in zip_list:\n",
    "            zip_file_name = os.path.basename(zip_file)\n",
    "        #     print(zip_file_name)\n",
    "            dir_to_extract = extracting_dir + f'texturehaven_{zip_file_name}'.replace('_jpg', '')\n",
    "            with ZipFile(f'{zip_dir}{zip_file_name}', 'r') as zip_ref:\n",
    "                zip_ref.extractall(dir_to_extract[:-4])\n",
    "                fix_maptypes(dir_to_extract[:-4], 'texturehaven')\n",
    "                \n",
    "                if not 'cobblestone_color_2k' in dir_to_extract and not 'texturehaven_roof_slates_03_2k' in dir_to_extract:\n",
    "                    fix_color_maps(dir_to_extract[:-4])\n",
    "    \n",
    "    \n",
    "    \n",
    "    get_links_to_csv(base_url = \"https://texturehaven.com/textures/\",\n",
    "                     file_name_to_store = f'{csv_directory}/texturehaven_links.csv',\n",
    "                     anchor_grid_id = \"item-grid\",\n",
    "                     )\n",
    "\n",
    "    get_download_links_to_csv(csv_name_with_links = f'{csv_directory}/texturehaven_links.csv', \n",
    "                              resolution = '8k', \n",
    "                              xPath = '//*[@id=\"preview-download\"]/div[2]/div[1]/div[3]/div[4]/a[1]'\n",
    "                             )\n",
    "\n",
    "    download_zip_files(csv_with_download_links = f'{csv_directory}/texturehaven_links.csv', \n",
    "                   dir_output = './texturehaven_zip/'\n",
    "                  )\n",
    "\n",
    "    extract_files(zip_dir = './texturehaven_zip/', \n",
    "                  extracting_dir = f'{directory_output}/'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cgbookcase(directory_output, csv_directory):\n",
    "    \n",
    "    if not os.path.exists(directory_output):\n",
    "            os.mkdir(directory_output)\n",
    "        \n",
    "    if not os.path.exists(csv_directory):\n",
    "            os.mkdir(csv_directory)\n",
    "        \n",
    "    def download_file(url, save_path, chunk_size=1024):\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(save_path, 'wb') as fd:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                fd.write(chunk)\n",
    "            \n",
    "            \n",
    "    def check_exists_by_class(element_class, webdriver):\n",
    "        try:\n",
    "            webdriver.find_element_by_class_name(element_class)\n",
    "        except NoSuchElementException:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "    def get_links_to_csv(base_url, file_name_to_store, anchor_grid_id, anchor_css_selector=None):\n",
    "        driver = webdriver.Chrome()\n",
    "        i = 1\n",
    "        texture_csv_rows = []\n",
    "\n",
    "        while True:\n",
    "            base_url = f\"https://www.cgbookcase.com/textures/?category=All&resolution=2&page={i}&color=all&search=\"\n",
    "            driver.get(base_url)\n",
    "            i = i + 1\n",
    "            anchor_grid = driver.find_element_by_id(anchor_grid_id)\n",
    "\n",
    "            if anchor_css_selector == None:\n",
    "                anchor_tags = anchor_grid.find_elements_by_css_selector(\"a\")\n",
    "            else:\n",
    "                anchor_tags = anchor_grid.find_elements_by_css_selector(anchor_css_selector)\n",
    "\n",
    "            button_class = 'fas.fa-angle-right'\n",
    "\n",
    "            if check_exists_by_class(button_class, driver):\n",
    "                for anchor in anchor_tags:\n",
    "                    parsed_url = anchor.get_attribute(\"href\")\n",
    "                    title = parsed_url.split('/').pop()\n",
    "                    csv_row = {\n",
    "                        'title': title.lower(),\n",
    "                        'url': parsed_url,\n",
    "                    }\n",
    "                    texture_csv_rows.append(csv_row)\n",
    "            else:\n",
    "                for anchor in anchor_tags:\n",
    "                    parsed_url = anchor.get_attribute(\"href\")\n",
    "                    title = parsed_url.split('/').pop()\n",
    "                    csv_row = {\n",
    "                        'title': title.lower(),\n",
    "                        'url': parsed_url,\n",
    "                    }\n",
    "                    texture_csv_rows.append(csv_row)\n",
    "                break\n",
    "\n",
    "        driver.close()\n",
    "                # print(texture_csv_rows)\n",
    "\n",
    "        texture_csv = pd.DataFrame(texture_csv_rows)\n",
    "        texture_csv.to_csv(file_name_to_store)\n",
    "\n",
    "    def check_for_4k_res(anchor_tags):\n",
    "        for anchor in anchor_tags:\n",
    "                    url = anchor.get_attribute(\"href\")\n",
    "                    if '4K' in url:\n",
    "                        return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def check_for_3k_res(anchor_tags):\n",
    "        for anchor in anchor_tags:\n",
    "                    url = anchor.get_attribute(\"href\")\n",
    "                    if '3K' in url:\n",
    "                        return True\n",
    "        return False\n",
    "    \n",
    "\n",
    "    def get_download_links_to_csv(csv_name_with_links, resolution, csv_for_download_links, xPath):\n",
    "        texture_csv_rows = []\n",
    "\n",
    "        driver = webdriver.Chrome()\n",
    "\n",
    "        with open(csv_name_with_links, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "\n",
    "            for row in reader:\n",
    "                driver.get(row['url'])\n",
    "                anchor_grid = driver.find_element_by_xpath('//*[@id=\"view-downloadLinks\"]')\n",
    "                anchor_tags = anchor_grid.find_elements_by_css_selector(\"a\")\n",
    "                propertys_urls = []\n",
    "                \n",
    "                if check_for_4k_res(anchor_tags):\n",
    "                    for anchor in anchor_tags:\n",
    "                        url = anchor.get_attribute(\"href\")\n",
    "                        if '4K' in url:\n",
    "                            csv_row = {\n",
    "                                'title': row['title'],\n",
    "                                'url': row['url'],\n",
    "                                'resolution': '4k',\n",
    "                                'property': url.split('_').pop(),\n",
    "                                'download_url': url\n",
    "                            }\n",
    "                        texture_csv_rows.append(csv_row)\n",
    "                elif check_for_3k_res(anchor_tags):\n",
    "                    for anchor in anchor_tags:\n",
    "                        url = anchor.get_attribute(\"href\")\n",
    "                        if '3K' in url:\n",
    "                            csv_row = {\n",
    "                                'title': row['title'],\n",
    "                                'url': row['url'],\n",
    "                                'resolution': '3k',\n",
    "                                'property': url.split('_').pop(),\n",
    "                                'download_url': url\n",
    "                            }\n",
    "                        texture_csv_rows.append(csv_row)\n",
    "                else:\n",
    "                    for anchor in anchor_tags:\n",
    "                        url = anchor.get_attribute(\"href\")\n",
    "                        if '2K' in url:\n",
    "                            csv_row = {\n",
    "                                'title': row['title'],\n",
    "                                'url': row['url'],\n",
    "                                'resolution': '2k',\n",
    "                                'property': url.split('_').pop(),\n",
    "                                'download_url': url\n",
    "                            }\n",
    "                            texture_csv_rows.append(csv_row)\n",
    "                        \n",
    "\n",
    "        driver.close()\n",
    "\n",
    "        texture_csv = pd.DataFrame(texture_csv_rows)\n",
    "        texture_csv.to_csv(csv_for_download_links)\n",
    "        \n",
    "\n",
    "    def fix_maptypes(map_dir, source_name):\n",
    "        list_of_maps = os.listdir(map_dir)\n",
    "        \n",
    "        for map_type in list_of_maps:\n",
    "            map_file_name = os.path.basename(map_type)\n",
    "            \n",
    "            for map_key, map_label in texture_map_labels[source_name].items():\n",
    "\n",
    "                if map_key in map_file_name:\n",
    "                    old_name = map_file_name\n",
    "                    map_file_name = map_file_name.replace(map_key, map_label)\n",
    "                    os.rename(f'{map_dir}/{old_name}', f'{map_dir}/{map_file_name.lower()}')\n",
    "        \n",
    "        \n",
    "    def download_files(csv_with_download_links, dir_output):\n",
    "        file_path_template = re.compile(r'\\/([^/]+$)')\n",
    "\n",
    "        with open(csv_with_download_links, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            first_row = next(reader)\n",
    "            same_dir_list = []\n",
    "            same_dir_list.append(first_row)\n",
    "            title = f'cgbookcase_{first_row[\"title\"]}_{first_row[\"resolution\"]}'.lower()\n",
    "\n",
    "            for row in reader:\n",
    "\n",
    "                if row['title'] in title:\n",
    "                    same_dir_list.append(row)\n",
    "                else:\n",
    "                    i = 0\n",
    "\n",
    "                    for dir_item in same_dir_list:\n",
    "\n",
    "                        if i == 0:\n",
    "                            title = title.replace('-', '--')\n",
    "                            os.mkdir(f'{dir_output}{title}')\n",
    "\n",
    "                        i = 1\n",
    "                        save_path = f\"{dir_output}{title}/{title}_{dir_item['property']}\"\n",
    "#                         print(f\"{dir_output} and file path: {title}/{dir_item['property']}\")\n",
    "                        download_file(dir_item['download_url'], save_path)\n",
    "    \n",
    "                    fix_maptypes(f\"{dir_output}{title}\", 'cgbookcase')\n",
    "                    same_dir_list = []\n",
    "                    same_dir_list.append(row)\n",
    "                    title = f'cgbookcase_{row[\"title\"]}_{row[\"resolution\"]}'.lower()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def extract_files(zip_dir, extracting_dir):\n",
    "        zip_list = os.listdir(zip_dir)\n",
    "\n",
    "        for zip_file in zip_list:\n",
    "            zip_file_name = os.path.basename(zip_file)\n",
    "        #     print(zip_file_name)\n",
    "            dir_to_extract = extracting_dir + zip_file_name\n",
    "            with ZipFile(zip_dir + zip_file_name, 'r') as zip_ref:\n",
    "                zip_ref.extractall(dir_to_extract[:-4])\n",
    "\n",
    "                \n",
    "    def delete_folders_with_one_picture(dir_of_folders):\n",
    "        folders = os.listdir(dir_of_folders)\n",
    "        for folder in folders:\n",
    "            dir_of_folder = f'{dir_of_folders}{os.path.basename(folder)}'\n",
    "            if len(os.listdir(dir_of_folder)) == 1:\n",
    "                shutil.rmtree(dir_of_folder)    \n",
    "                \n",
    "                \n",
    "    get_links_to_csv(base_url = \"https://www.cgbookcase.com/textures/?category=All&resolution=2&page=1&color=all&search=\",\n",
    "                 file_name_to_store = f\"{csv_directory}/cgbookcase_links.csv\",\n",
    "                 anchor_grid_id = \"textures-list\"\n",
    "                 )\n",
    "    \n",
    "    get_download_links_to_csv(csv_name_with_links = f\"{csv_directory}/cgbookcase_links.csv\", \n",
    "                          resolution = '2k', \n",
    "                          csv_for_download_links = f\"{csv_directory}/cgbookcase_links.csv\",\n",
    "                          xPath = '//*[@id=\"preview-download\"]/div[2]/div[1]/div[3]/div[2]/a[1]'\n",
    "                         )\n",
    "    \n",
    "    download_files(csv_with_download_links = f\"{csv_directory}/cgbookcase_links.csv\", \n",
    "               dir_output = f'{directory_output}/'\n",
    "              )\n",
    "    \n",
    "    extract_files(zip_dir = './cgbookcase_zip/', \n",
    "              extracting_dir = directory_output\n",
    "             )\n",
    "    \n",
    "    delete_folders_with_one_picture(dir_of_folders = f'{directory_output}/')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goodtextures(directory_output, csv_directory):\n",
    "    \n",
    "    if not os.path.exists(directory_output):\n",
    "            os.mkdir(directory_output)\n",
    "        \n",
    "    if not os.path.exists(csv_directory):\n",
    "            os.mkdir(csv_directory)\n",
    "        \n",
    "    def download_files(url, save_path, chunk_size=1024):\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(save_path, 'wb') as fd:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                fd.write(chunk)\n",
    "            \n",
    "\n",
    "    def get_download_links_straight_to_csv(base_url, file_name_to_store, anchor_grid_xpath, resolution, anchor_css_selector=None):\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(base_url)\n",
    "\n",
    "        anchor_grid = driver.find_element_by_xpath(anchor_grid_xpath)\n",
    "        parsed_urls = []\n",
    "\n",
    "        if anchor_css_selector == None:\n",
    "            anchor_divs = anchor_grid.find_elements_by_css_selector(\".row\")\n",
    "\n",
    "            for div in anchor_divs:\n",
    "                for anchor in div.find_elements_by_css_selector(\"a\"):\n",
    "                    parsed_urls.append(anchor.get_attribute(\"href\"))\n",
    "        else:\n",
    "            anchor_tags = anchor_grid.find_elements_by_css_selector(anchor_css_selector)\n",
    "\n",
    "        texture_csv_rows = []\n",
    "        download_urls = []\n",
    "\n",
    "        for url in parsed_urls:\n",
    "            driver.get(url)\n",
    "            divs = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]')\n",
    "            containers_list = divs.find_elements_by_css_selector('div.container')\n",
    "\n",
    "            i = 1\n",
    "            for container in containers_list:\n",
    "                download_anchor = container.find_element_by_xpath(f'/html/body/div[2]/div/div[1]/div[{i}]/div/div/div/div[2]/div/p[4]/a')\n",
    "                download_url = download_anchor.get_attribute(\"href\")\n",
    "                i = i + 1\n",
    "                title = download_url.split('/')[-1].split('_materials')[0]\n",
    "                csv_row = {\n",
    "                    'title': title.lower(),\n",
    "                    'url': url,\n",
    "                    'resolution': resolution,\n",
    "                    'download_url': download_url\n",
    "                }\n",
    "                texture_csv_rows.append(csv_row )\n",
    "        driver.close()\n",
    "\n",
    "        texture_csv = pd.DataFrame(texture_csv_rows)\n",
    "        texture_csv.to_csv(file_name_to_store)\n",
    "\n",
    "    def download_zip_files(csv_with_download_links, dir_output):\n",
    "        \n",
    "        if not os.path.exists(dir_output):\n",
    "            os.mkdir(dir_output)\n",
    "            \n",
    "        file_path_template = re.compile(r'\\/([^/]+$)')\n",
    "\n",
    "        with open(csv_with_download_links, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                file_path = file_path_template.search(row['download_url']).group(1).lower()\n",
    "                download_files(row['download_url'], f'{dir_output}{file_path}_{row[\"resolution\"]}')\n",
    "\n",
    "                \n",
    "    def move_files_one_layer_up(dir_of_folder):\n",
    "        \n",
    "            for inner_folder in os.listdir(dir_of_folder):\n",
    "                inner_folder_path = f'{dir_of_folder}/{os.path.basename(inner_folder)}'\n",
    "                for file in os.listdir(inner_folder_path):\n",
    "                    shutil.move(f'{inner_folder_path}/{os.path.basename(file)}', \n",
    "                                f'{dir_of_folder}/goodtextures_{os.path.basename(file)}')\n",
    "            shutil.rmtree(inner_folder_path)\n",
    "            \n",
    "\n",
    "    def fix_maptypes(map_dir, source_name):\n",
    "        list_of_maps = os.listdir(map_dir)\n",
    "        \n",
    "        for map_type in list_of_maps:\n",
    "            map_file_name = os.path.basename(map_type)\n",
    "            \n",
    "            for map_key, map_label in texture_map_labels[source_name].items():\n",
    "                old_name = map_file_name\n",
    "                map_file_name = map_file_name.replace(map_key, map_label)\n",
    "                map_file_name_array = map_file_name.split('_')\n",
    "                map_file_name_peace = f'2k_{map_file_name_array[-1]}'\n",
    "                map_file_name = map_file_name.replace(map_file_name_array[-1], map_file_name_peace)\n",
    "                os.rename(f'{map_dir}/{old_name}', f'{map_dir}/{map_file_name.lower()}')\n",
    "            \n",
    "            \n",
    "    def extract_files(zip_dir, extracting_dir):\n",
    "        zip_list = os.listdir(zip_dir)\n",
    "\n",
    "        for zip_file in zip_list:\n",
    "            zip_file_name = os.path.basename(zip_file)\n",
    "    #         print(zip_file_name)\n",
    "            dir_to_extract = extracting_dir + 'goodtextures_' + zip_file_name\n",
    "            try:\n",
    "                with ZipFile(zip_dir + zip_file_name, 'r') as zip_ref:\n",
    "                    dir_to_extract = dir_to_extract.replace('.zip','')\n",
    "                    zip_ref.extractall(dir_to_extract)\n",
    "                    move_files_one_layer_up(dir_to_extract)\n",
    "                    fix_maptypes(dir_to_extract, 'goodtextures')\n",
    "            except BadZipFile:\n",
    "                os.remove(zip_dir + zip_file_name)\n",
    "\n",
    "            \n",
    "#     get_download_links_straight_to_csv(base_url = \"https://www.goodtextures.com/blog/22/pbr-texture-categories\",\n",
    "#                  file_name_to_store = f\"{csv_directory}/goodtextures_links.csv\",\n",
    "#                  anchor_grid_xpath = \"/html/body/div[2]/div/div[1]\",\n",
    "#                  resolution = '2k'              \n",
    "#                  )\n",
    "\n",
    "    \n",
    "#     download_zip_files(csv_with_download_links = f\"{csv_directory}/goodtextures_links.csv\",\n",
    "#                dir_output = './goodtextures_zip/'\n",
    "#               )\n",
    "    \n",
    "    \n",
    "    extract_files(zip_dir = './goodtextures_zip/', \n",
    "                  extracting_dir = f'{directory_output}/'\n",
    "                 )\n",
    "                  \n",
    "        \n",
    "#     move_files_one_layer_up(dir_of_folders = './unzipped/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_archinspiration(directory_output, csv_directory):\n",
    "    \n",
    "    if not os.path.exists(directory_output):\n",
    "            os.mkdir(directory_output)\n",
    "        \n",
    "    if not os.path.exists(csv_directory):\n",
    "            os.mkdir(csv_directory)\n",
    "        \n",
    "    def download_files(url, save_path, chunk_size=1024):\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(save_path, 'wb') as fd:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                fd.write(chunk)\n",
    "            \n",
    "\n",
    "    def get_links_to_csv(base_url, file_name_to_store, anchor_grid_class_name, anchor_css_selector=None):\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(base_url)\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        driver.find_element_by_class_name(\"sqs-block-button-element--small.sqs-block-button-element.pagination-loadMore\").click()\n",
    "\n",
    "        anchor_grid = driver.find_element_by_class_name(anchor_grid_class_name)\n",
    "\n",
    "        if anchor_css_selector == None:\n",
    "            anchor_tags = anchor_grid.find_elements_by_css_selector(\"a\")\n",
    "        else:\n",
    "            anchor_tags = anchor_grid.find_elements_by_css_selector(anchor_css_selector)\n",
    "\n",
    "        texture_csv_rows = []\n",
    "\n",
    "        for anchor in anchor_tags:\n",
    "            parsed_url = anchor.get_attribute(\"href\")\n",
    "            title = parsed_url.split('/')[-1]\n",
    "            csv_row = {\n",
    "                'title': title.lower().replace('-', '--'),\n",
    "                'url': parsed_url\n",
    "            }\n",
    "            texture_csv_rows.append(csv_row )\n",
    "\n",
    "        driver.close()\n",
    "        # print(texture_csv_rows)\n",
    "\n",
    "        texture_csv = pd.DataFrame(texture_csv_rows)\n",
    "        texture_csv.to_csv(file_name_to_store)\n",
    "\n",
    "\n",
    "    #'//*[@id=\"preview-download\"]/div[2]/div[1]/div[3]/div[2]/a[1]'\n",
    "    def get_download_links_to_csv(csv_name_with_links, resolution, csv_for_download_links, class_name):\n",
    "        texture_csv_rows = []\n",
    "        driver = webdriver.Chrome()\n",
    "\n",
    "        with open(csv_name_with_links, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                driver.get(row['url'])\n",
    "                download_anchors = driver.find_elements_by_class_name(class_name)\n",
    "                for download_anchor in download_anchors:\n",
    "                    if 'FREE' in download_anchor.text:\n",
    "                        download_url = download_anchor.get_attribute(\"href\")\n",
    "                        csv_row = {\n",
    "                            'title': row['title'],\n",
    "                            'url': row['url'],\n",
    "                            'resolution': '1k',\n",
    "                            'download_url': download_url\n",
    "                        }\n",
    "                        texture_csv_rows.append(csv_row )\n",
    "\n",
    "        driver.close()\n",
    "\n",
    "        texture_csv = pd.DataFrame(texture_csv_rows)\n",
    "        texture_csv.to_csv(csv_for_download_links)\n",
    "\n",
    "\n",
    "    def download_zip_files(csv_with_download_links, dir_output):\n",
    "        \n",
    "        if not os.path.exists(dir_output):\n",
    "            os.mkdir(dir_output)\n",
    "\n",
    "        with open(csv_with_download_links, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "    #             file_path = file_path_template.search(row['title'])\n",
    "                save_path = f\"{dir_output}archinspirations_{row['title']}_{row['resolution']}\"\n",
    "                download_files(row['download_url'], save_path)\n",
    "\n",
    "    def fix_maptypes(map_dir, source_name):\n",
    "        list_of_maps = os.listdir(map_dir)\n",
    "        \n",
    "        for map_type in list_of_maps:\n",
    "            map_file_name = os.path.basename(map_type)\n",
    "            \n",
    "            for map_key, map_label in texture_map_labels[source_name].items():\n",
    "                old_name = map_file_name\n",
    "                map_file_name = map_file_name.replace(map_key, map_label)\n",
    "                os.rename(f'{map_dir}/{old_name}', f'{map_dir}/{map_file_name.lower()}')\n",
    "            \n",
    "            \n",
    "    def move_files_one_layer_up(dir_of_folder):\n",
    "#     removing unnecessary files from the top layer\n",
    "        for file in os.listdir(dir_of_folder):\n",
    "            file_path = f'{dir_of_folder}/{os.path.basename(file)}'\n",
    "            for item in os.listdir(dir_of_folder):\n",
    "                if 'maps' not in os.path.basename(item):\n",
    "                    os.remove(f'{dir_of_folder}/{item}')\n",
    "#         moving files to the upper layer\n",
    "        for file in os.listdir(dir_of_folder):\n",
    "            file_path = f'{dir_of_folder}/{os.path.basename(file)}'\n",
    "            for item in os.listdir(f'{dir_of_folder}/maps'):\n",
    "                shutil.move(f'{dir_of_folder}/maps/{os.path.basename(item)}', \n",
    "                            f'{dir_of_folder}/{os.path.basename(item)}')\n",
    "\n",
    "        shutil.rmtree(f'{dir_of_folder}/maps')\n",
    "        fix_maptypes(dir_of_folder, 'archinspirations')\n",
    "            \n",
    "            \n",
    "    def extract_files(zip_dir, extracting_dir):\n",
    "        zip_list = os.listdir(zip_dir)\n",
    "\n",
    "        for zip_file in zip_list:\n",
    "            zip_file_name = os.path.basename(zip_file)\n",
    "            dir_to_extract = extracting_dir + zip_file_name\n",
    "            try:\n",
    "                if zip_file_name in 'archinspirations_marble-ai-01b_1k':\n",
    "                    os.remove(zip_dir + zip_file_name)\n",
    "                else:\n",
    "                    with ZipFile(zip_dir + zip_file_name, 'r') as zip_ref:\n",
    "                        zip_ref.extractall(dir_to_extract)\n",
    "                        move_files_one_layer_up(dir_to_extract)\n",
    "                        fix_maptypes(dir_to_extract, 'archinspirations')\n",
    "            except BadZipFile:\n",
    "                os.remove(zip_dir + zip_file_name)\n",
    "\n",
    "#             shutil.rmtree(f'{dir_of_folder}/maps')\n",
    "            \n",
    "\n",
    "    get_links_to_csv(base_url = \"https://www.archinspirations.com/materials\",\n",
    "                 file_name_to_store = f\"{csv_directory}/archinspirations_links.csv\",\n",
    "                 anchor_grid_class_name = 'summary-item-list.sqs-gallery.sqs-gallery-design-autogrid',\n",
    "                 anchor_css_selector = 'a.summary-thumbnail-container.sqs-gallery-image-container'\n",
    "                 )\n",
    "    \n",
    "    get_download_links_to_csv(csv_name_with_links = f\"{csv_directory}/archinspirations_links.csv\", \n",
    "                          resolution = '1k', \n",
    "                          csv_for_download_links = f\"{csv_directory}/archinspirations_links.csv\",\n",
    "                          class_name = 'sqs-block-button-element--small.sqs-block-button-element'\n",
    "                         )\n",
    "    \n",
    "    download_zip_files(csv_with_download_links = f\"{csv_directory}/archinspirations_links.csv\", \n",
    "               dir_output = './archinspirations_zip/'\n",
    "              )\n",
    "    \n",
    "    extract_files(zip_dir = './archinspirations_zip/',\n",
    "              extracting_dir = f'{directory_output}/'\n",
    "             )\n",
    "    \n",
    "    # before that you have to fix marble-ai-01b folder, because this folder holds 2 folders,\n",
    "    # so just move one of those folders one layer up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FreePBR(directory_output, csv_directory):\n",
    "    \n",
    "    if not os.path.exists(directory_output):\n",
    "            os.mkdir(directory_output)\n",
    "        \n",
    "    if not os.path.exists(csv_directory):\n",
    "            os.mkdir(csv_directory)\n",
    "        \n",
    "    def download_files(url, save_path, chunk_size=1024):\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(save_path, 'wb') as fd:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                fd.write(chunk)\n",
    "\n",
    "\n",
    "    def get_links_to_csv(base_url, file_name_to_store, anchor_grid_xpath, resolution, anchor_css_selector=None):\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(base_url)\n",
    "\n",
    "        texture_csv_rows = []\n",
    "\n",
    "        category_list = driver.find_element_by_xpath('//*[@id=\"woocommerce_product_categories-2\"]/ul')\n",
    "        category_anchors = category_list.find_elements_by_css_selector(\"a\")\n",
    "\n",
    "        category_anchors.pop(0)#we don't need the first anchor\n",
    "        category_urls = []\n",
    "\n",
    "        # we have to collect urls from anchor tags in separate way, because anchor tags must be attached to the DOM\n",
    "        for category_anchor in category_anchors:\n",
    "            category_urls.append(category_anchor.get_attribute(\"href\")) \n",
    "\n",
    "        for category_url in category_urls:\n",
    "            driver.get(category_url)\n",
    "            anchor_grid = driver.find_element_by_xpath(anchor_grid_xpath)\n",
    "\n",
    "            if anchor_css_selector == None:\n",
    "                anchor_tags = anchor_grid.find_elements_by_css_selector(\"a\")\n",
    "            else:\n",
    "                anchor_tags = anchor_grid.find_elements_by_css_selector(anchor_css_selector)\n",
    "\n",
    "            for anchor in anchor_tags:\n",
    "                parsed_url = anchor.get_attribute(\"href\")\n",
    "                title = parsed_url.split('/')[-2]\n",
    "                csv_row = {\n",
    "                    'title': f'freepbr_{title.lower().replace(\"-\", \"--\")}_{resolution}',\n",
    "                    'url': parsed_url,\n",
    "                    'resolution': resolution\n",
    "                }\n",
    "                texture_csv_rows.append(csv_row )\n",
    "\n",
    "        driver.close()\n",
    "            # print(texture_csv_rows)\n",
    "\n",
    "        texture_csv = pd.DataFrame(texture_csv_rows)\n",
    "        texture_csv.to_csv(file_name_to_store)\n",
    "\n",
    "\n",
    "    #'//*[@id=\"preview-download\"]/div[2]/div[1]/div[3]/div[2]/a[1]'\n",
    "    def get_download_links_to_csv(csv_name_with_links, resolution, csv_for_download_links, xPath):\n",
    "        texture_csv_rows = []\n",
    "\n",
    "        driver = webdriver.Chrome()\n",
    "\n",
    "        with open(csv_name_with_links, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                driver.get(row['url'])\n",
    "                try:\n",
    "                    download_anchor = driver.find_element_by_xpath(xPath)\n",
    "                    download_url = download_anchor.get_attribute(\"href\")\n",
    "                    csv_row = {\n",
    "                        'title': row['title'],\n",
    "                        'url': row['url'],\n",
    "                        'resolution': resolution,\n",
    "                        'download_url': download_url\n",
    "                    }\n",
    "                    texture_csv_rows.append(csv_row )\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "        driver.close()\n",
    "\n",
    "        texture_csv = pd.DataFrame(texture_csv_rows)\n",
    "        texture_csv.to_csv(csv_for_download_links)\n",
    "\n",
    "\n",
    "    def download_zip_files(csv_with_download_links, dir_output):\n",
    "        \n",
    "        if not os.path.exists(dir_output):\n",
    "            os.mkdir(dir_output)\n",
    "\n",
    "        with open(csv_with_download_links, newline='') as csvfile:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "    #             file_path = file_path_template.search(row['title'])\n",
    "                save_path = f\"{dir_output}{row['title']}\"\n",
    "                download_files(row['download_url'], save_path)\n",
    "    \n",
    "    \n",
    "    def fix_maptypes(map_dir, source_name):\n",
    "        list_of_maps = os.listdir(map_dir)\n",
    "        \n",
    "        for map_type in list_of_maps:\n",
    "            map_file_name = os.path.basename(map_type)\n",
    "            name_changed = False\n",
    "            \n",
    "            for map_key, map_label in texture_map_labels[source_name].items():\n",
    "\n",
    "                if map_key in map_file_name:\n",
    "                    old_name = map_file_name\n",
    "                    map_file_name = map_file_name.replace(map_key, map_label)\n",
    "                    os.rename(f'{map_dir}/{old_name}', f'{map_dir}/{source_name}_2k_{map_file_name.lower().replace(\"-\", \"--\")}')\n",
    "                    name_changed = True\n",
    "            if not name_changed:\n",
    "                os.rename(f'{map_dir}/{map_file_name}', f'{map_dir}/{source_name}_2k_{map_file_name.lower().replace(\"-\", \"--\")}')\n",
    "    \n",
    "    def move_files_one_layer_up(dir_of_folder):\n",
    "        inner_folder_path = f'{dir_of_folder}/{os.path.basename(os.listdir(dir_of_folder)[0])}'\n",
    "\n",
    "        if os.path.isdir(inner_folder_path):\n",
    "\n",
    "            for file in os.listdir(inner_folder_path):\n",
    "                shutil.move(f'{inner_folder_path}/{os.path.basename(file)}', \n",
    "                            f'{dir_of_folder}/{os.path.basename(file)}')\n",
    "            shutil.rmtree(inner_folder_path)\n",
    "            \n",
    "\n",
    "    def extract_files(zip_dir, extracting_dir):\n",
    "        zip_list = os.listdir(zip_dir)\n",
    "\n",
    "        for zip_file in zip_list:\n",
    "            zip_file_name = os.path.basename(zip_file)\n",
    "        #     print(zip_file_name)\n",
    "            try:\n",
    "                dir_to_extract = extracting_dir + zip_file_name\n",
    "                with ZipFile(zip_dir + zip_file_name, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(dir_to_extract)\n",
    "                    move_files_one_layer_up(dir_to_extract)\n",
    "                    fix_maptypes(dir_to_extract, 'freepbr')\n",
    "            except BadZipFile:\n",
    "                continue\n",
    "        #     print('UNZIPPED')\n",
    "\n",
    "        # print('done')    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    get_links_to_csv(base_url = \"https://freepbr.com/\",\n",
    "                 file_name_to_store = f\"{csv_directory}/freepbr_links.csv\",\n",
    "                 anchor_grid_xpath = '//*[@id=\"main\"]/ul',\n",
    "                 anchor_css_selector = \"a.button.product_type_simple\",\n",
    "                 resolution = '2k'\n",
    "                 )\n",
    "    \n",
    "    get_download_links_to_csv(csv_name_with_links = f\"{csv_directory}/freepbr_links.csv\", \n",
    "                          resolution = '2k', \n",
    "                          csv_for_download_links = f\"{csv_directory}/freepbr_links.csv\",\n",
    "                          xPath = '/html/body/div[1]/div[2]/div/div[2]/main/div[2]/div[2]/div[1]/div/ul/li[3]/a'\n",
    "                         )\n",
    "    \n",
    "    download_zip_files(csv_with_download_links = f\"{csv_directory}/freepbr_links.csv\", \n",
    "               dir_output = './freepbr_zip/'\n",
    "              )\n",
    "    \n",
    "    extract_files(zip_dir = './freepbr_zip/', \n",
    "              extracting_dir = f'{directory_output}/'\n",
    "             )\n",
    "    \n",
    "#     move_files_one_layer_up(\n",
    "#     dir_of_folders = './unzipped/'\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cc0textures(directory_output, csv_directory, resolution = '8K'):\n",
    "    \n",
    "    if not os.path.exists(directory_output):\n",
    "            os.mkdir(directory_output)\n",
    "        \n",
    "    if not os.path.exists(csv_directory):\n",
    "            os.mkdir(csv_directory)\n",
    "        \n",
    "    source_name = 'cc0textures'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    data  = Request('https://cc0textures.com/api/v1/downloads_csv', headers=headers)\n",
    "    data = urlopen(data)\n",
    "    data = pd.read_csv(data) \n",
    "    data.head()\n",
    "\n",
    "    data.to_csv(f\"{csv_directory}/c00textures_links.csv\")\n",
    "\n",
    "    def download_url(url, save_path, chunk_size=1024):\n",
    "        r = requests.get(url, stream=True)\n",
    "        with open(save_path, 'wb') as fd:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                fd.write(chunk)\n",
    "\n",
    "    def random_crop(image):\n",
    "        return tf.Session().run(tf.image.random_crop(image, size=[500, 500, 3]))\n",
    "\n",
    "\n",
    "    \n",
    "    download_attribute = '8K-JPG'\n",
    "    \n",
    "    if not resolution == '8K':\n",
    "        download_attribute = f'{resolution}K-JPG'\n",
    "        \n",
    "    metadata = pd.read_csv(f\"{csv_directory}/c00textures_links.csv\")\n",
    "    metadata = metadata[metadata['DownloadAttribute'] == download_attribute]\n",
    "    metadata['material'] = metadata['AssetID'].str.extract(r'([A-Za-z]+)')\n",
    "    metadata['material'].value_counts().head(20)\n",
    "\n",
    "    material = 'PavingStones'\n",
    "    dir_zip_output = './c00textures_zip'\n",
    "\n",
    "    if not os.path.exists(dir_zip_output): \n",
    "        os.mkdir(dir_zip_output)\n",
    "\n",
    "    # https://help.cc0textures.com/doku.php?id=api_v1:start\n",
    "    metadata = pd.read_csv(f\"{csv_directory}/c00textures_links.csv\")\n",
    "    metadata['material'] = metadata['AssetID'].str.extract(r'([A-Za-z]+)')\n",
    "    metadata = metadata[metadata['DownloadAttribute'] == download_attribute]\n",
    "    metadata = metadata[metadata['material'] == material]\n",
    "\n",
    "    file_path_template = re.compile(r'\\/([^/]+$)')\n",
    "    for index, row in metadata.iterrows():    \n",
    "        url = row['RawDownloadLink']\n",
    "        file_path = f'{source_name}_{file_path_template.search(url).group(1).replace(\"-JPG.zip\", \"\").lower().replace(\"-\", \"--\")}'\n",
    "        download_url(url, f'{dir_zip_output}/{file_path}')\n",
    "        \n",
    "        \n",
    "    def fix_maptypes(map_dir, source_name):\n",
    "        list_of_maps = os.listdir(map_dir)\n",
    "        \n",
    "        for map_type in list_of_maps:\n",
    "            map_file_name = os.path.basename(map_type)\n",
    "            name_changed = False\n",
    "            \n",
    "            for map_key, map_label in texture_map_labels[source_name].items():\n",
    "\n",
    "                if map_key in map_file_name:\n",
    "                    old_name = map_file_name\n",
    "                    map_file_name = map_file_name.replace(map_key, map_label)\n",
    "                    os.rename(f'{map_dir}/{old_name}', f'{map_dir}/{source_name}_{map_file_name.lower().replace(\"-\", \"--\")}')\n",
    "                    name_changed = True\n",
    "            if not name_changed:\n",
    "                os.rename(f'{map_dir}/{map_file_name}', f'{map_dir}/{source_name}_{map_file_name.lower().replace(\"-\", \"--\")}')\n",
    "        \n",
    "        \n",
    "    def extract_files(zip_dir, extracting_dir):\n",
    "        zip_list = os.listdir(zip_dir)\n",
    "\n",
    "        for zip_file in zip_list:\n",
    "            zip_file_name = os.path.basename(zip_file)\n",
    "        #     print(zip_file_name)\n",
    "            try:\n",
    "                dir_to_extract = extracting_dir + zip_file_name\n",
    "                with ZipFile(zip_dir + zip_file_name, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(dir_to_extract)\n",
    "                    fix_maptypes(dir_to_extract, 'cc0textures')\n",
    "            except BadZipFile:\n",
    "                continue\n",
    "        \n",
    "        \n",
    "    extract_files(zip_dir = f'{dir_zip_output}/', \n",
    "                  extracting_dir = f'{directory_output}/'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_map_labels = {\n",
    "    'texturehaven': {\n",
    "        'AO': 'ao',\n",
    "        'rough_ao': 'roughness_ao',\n",
    "        'Rough_ao': 'roughness_ao',\n",
    "        'diff': 'color',\n",
    "        'Diff': 'color',\n",
    "        'Base_Color': 'color',\n",
    "        'basecolorolor': 'color',\n",
    "        'Col_01': 'color_01',\n",
    "        'col_01': 'color_01',\n",
    "        'Col_02': 'color_02',\n",
    "        'col_02': 'color_02',\n",
    "        'Col_03': 'color_03',\n",
    "        'col_03': 'color_03',\n",
    "        'Nor': 'normal',\n",
    "        'nor': 'normal',\n",
    "        'rough': 'roughness',\n",
    "        'Rough': 'roughness',\n",
    "        'disp': 'displacement',\n",
    "        'Disp': 'displacement',\n",
    "        'spec': 'specular',\n",
    "        'Spec': 'specular',\n",
    "        'bump': 'bump',\n",
    "        'Bump': 'bump' \n",
    "    },\n",
    "    'cgbookcase': {\n",
    "        'AO': 'ao',\n",
    "        'ao': 'ao',\n",
    "        'Color': 'color',\n",
    "        'Height': 'height',\n",
    "        'Normal': 'normal',\n",
    "        'Roughness': 'roughness'        \n",
    "    },\n",
    "    'goodtextures': {\n",
    "        'basecolor': 'color'\n",
    "    },\n",
    "    'archinspirations': {\n",
    "        'AO': 'ao',\n",
    "        'REFL': 'reflection',\n",
    "        'COLOR': 'color',\n",
    "        'NRM': 'normal',\n",
    "        'GLOSS': 'roughness',\n",
    "        'DISP': 'displacement',\n",
    "        'BUMP': 'bump'\n",
    "         \n",
    "    },\n",
    "    'freepbr': {\n",
    "        'albedo': 'color',\n",
    "        'basecolor': 'color',\n",
    "        'normal-ogl': 'normal'\n",
    "    },\n",
    "    'cc0textures': {\n",
    "        'AmbienientOcclusion': 'ao',\n",
    "        'Basecolor': 'color',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_get_functions = {\n",
    "    'texturehaven': get_texturehaven,\n",
    "    'cgbookcase': get_cgbookcase,\n",
    "    'goodtextures': get_goodtextures,\n",
    "    'archinspiration': get_archinspiration,\n",
    "    'freepbr': get_FreePBR,\n",
    "    'cc0textures': get_cc0textures\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source(source_name, directory_output, csv_directory):\n",
    "    \n",
    "    return source_get_functions[source_name](directory_output, csv_directory)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_labels = [\n",
    "                 'texturehaven', #resolution 8k\n",
    "                 'cgbookcase', #resolution mostly 4k, but there is 3k and 2k without any other higher options, so \n",
    "                               #it downloads the highest available resolution\n",
    "                 'goodtextures', # resolution 2k\n",
    "                 'archinspiration', # resolution 1k\n",
    "                 'freepbr', #resolution 2k\n",
    "                 'cc0textures' #by default it's 8k, but can be changed up to 16k, just by adding one more \n",
    "                               #argument (must be an integer)\n",
    "                               #which defines resolution\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_source('texturehaven', './all-textures', './all-csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_source('cgbookcase', './all-textures', './all-csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_source('goodtextures', './all-textures', './all-csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_source('archinspiration', './all-textures', './all-csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_source('freepbr', './all-textures', './all-csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_source('cc0textures', './all-textures', './all-csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
